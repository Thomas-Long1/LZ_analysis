{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9ada88e2-fcbd-430c-be34-37379049e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import uproot as up\n",
    "import awkward as ak\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm as tqdm\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cd7a8d3-8eec-42f2-8580-edefd97cd190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 11:46:05.211053: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=32, \n",
    "                        inter_op_parallelism_threads=32, \n",
    "                        allow_soft_placement=True)\n",
    "\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "393445d9-4300-46c3-8a21-7255b05173e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_decay(file):\n",
    "    \n",
    "    tfile= up.open(file)\n",
    "    events=tfile[\"Events\"]\n",
    "    area=events[\"pulsesODHG.pulseArea_phd\"]\n",
    "    area=area.array()\n",
    "    area=ak.flatten(area)\n",
    "    \n",
    "    coincidence=events[\"pulsesODHG.coincidence\"]\n",
    "    coincidence=coincidence.array()\n",
    "    coincidence=ak.flatten(coincidence)\n",
    "    \n",
    "    peak_time=events[\"pulsesODHG.peakTime_ns\"]\n",
    "    peak_time=peak_time.array()\n",
    "    peak_time=ak.flatten(peak_time)   \n",
    "\n",
    "    peak_amp=events[\"pulsesODHG.peakAmp\"]\n",
    "    peak_amp=peak_amp.array()\n",
    "    peak_amp=ak.flatten(peak_amp)\n",
    "    \n",
    "    t_25=events[\"pulsesODHG.areaFractionTime25_ns\"]\n",
    "    t_25=t_25.array()\n",
    "    t_25=ak.flatten(t_25)\n",
    "    \n",
    "    t_50=events[\"pulsesODHG.areaFractionTime50_ns\"]\n",
    "    t_50=t_50.array()\n",
    "    t_50=ak.flatten(t_50)\n",
    "    \n",
    "    t_75=events[\"pulsesODHG.areaFractionTime75_ns\"]\n",
    "    t_75=t_75.array()\n",
    "    t_75=ak.flatten(t_75)\n",
    "    \n",
    "    start=events[\"pulsesODHG.pulseStartTime_ns\"]\n",
    "    start=start.array()\n",
    "    start=ak.flatten(start)\n",
    "    \n",
    "    end=events[\"pulsesODHG.pulseEndTime_ns\"]\n",
    "    end=end.array()\n",
    "    end=ak.flatten(end)\n",
    "    \n",
    "    length=end-start\n",
    "    area_time=t_75/area\n",
    "    \n",
    "    return [area,coincidence,peak_time,peak_amp,t_25,t_50,t_75,length,area_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6c587b3-20de-4d2a-b8e4-484e987fa295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_decay(file):\n",
    "    \n",
    "    tfile= up.open(file)\n",
    "    events=tfile[\"Events\"]\n",
    "    \n",
    "    area=np.array(events[\"pulsesODHG.pulseArea_phd\"])\n",
    "    area=area.flatten()\n",
    "    \n",
    "    truth = tfile['RQMCTruth']\n",
    "    pp = np.array(truth['mcTruthEvent./mcTruthEvent.parentParticle'])\n",
    "    pp=pp.flatten()\n",
    "    \n",
    "    coincidence=np.array(events[\"pulsesODHG.coincidence\"])\n",
    "    coincidence=coincidence.flatten()\n",
    "    \n",
    "    \n",
    "    peak_time=np.array(events[\"pulsesODHG.peakTime_ns\"])\n",
    "    peak_time=peak_time.flatten()\n",
    "       \n",
    "\n",
    "    peak_amp=np.array(events[\"pulsesODHG.peakAmp\"])\n",
    "    peak_amp=peak_amp.flatten()\n",
    "    \n",
    "    \n",
    "    t_25=np.array(events[\"pulsesODHG.areaFractionTime25_ns\"])\n",
    "    t_25=t_25.flatten()\n",
    "    \n",
    "    \n",
    "    t_50=np.array(events[\"pulsesODHG.areaFractionTime50_ns\"])\n",
    "    t_50=t_50.flatten()\n",
    "    \n",
    "    \n",
    "    t_75=np.array(events[\"pulsesODHG.areaFractionTime75_ns\"])\n",
    "    t_75=t_75.flatten()\n",
    "    \n",
    "    \n",
    "    start=np.array(events[\"pulsesODHG.pulseStartTime_ns\"])\n",
    "    start=start.flatten()\n",
    "    \n",
    "    \n",
    "    end=np.array(events[\"pulsesODHG.pulseEndTime_ns\"])\n",
    "    end=end.flatten()\n",
    "    \n",
    "    \n",
    "    length=end-start\n",
    "    area_time=t_75/area\n",
    "    \n",
    "    return [area,coincidence,peak_time,peak_amp,t_25,t_50,t_75,length,area_time,pp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a4e5e601-e346-4dd7-ad61-63ef5280e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    columns={'Pulse Area' : [], 'Coincidence' : [], 'Peak Time' : [],'Peak Amp' : [], \n",
    "             '25% time' : [], '50% time' : [],'75% time' : [], 'Pulse Time' : [], 'time/area' : [],'tag' : []}\n",
    "    columns_exp=['Pulse Area','Coincidence','Peak Time','Peak Amp','25% time',\n",
    "             '50% time', '75% time', 'Pulse Time', 'time/area']\n",
    "    files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.14_DER_9.1.0_LZAP_5.4.1/od_internals/lzap_output/*')\n",
    "    with mp.Pool(30) as pool:\n",
    "            internals_data = list(tqdm.tqdm(pool.imap(functools.partial(data_decay),files),total=3000))\n",
    "    internals_data=pd.DataFrame(np.concatenate(internals_data,axis=1).T.tolist(),columns=columns)\n",
    "    internals_data=(((internals_data.explode(columns_exp)).reset_index().dropna())).drop(columns='index')\n",
    "    internals_data=internals_data[(internals_data[\"Pulse Area\"] > 5)&(internals_data['Coincidence'] >1)]\n",
    "    \n",
    "    files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.14_DER_9.1.0_LZAP_5.4.1/gdls_neutrons/lzap_output/*')\n",
    "    with mp.Pool(30) as pool:\n",
    "            neutron_data = list(tqdm.tqdm(pool.imap(functools.partial(data_decay),files),total=1962))\n",
    "    neutron_data=pd.DataFrame(np.concatenate(neutron_data,axis=1).T.tolist(),columns=columns)\n",
    "    neutron_data=(((neutron_data.explode(columns_exp)).reset_index().dropna())).drop(columns='index')\n",
    "    neutron_data=neutron_data[(neutron_data[\"Pulse Area\"] > 5)&(neutron_data['Coincidence'] >1)]\n",
    "    \n",
    "    files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.14_DER_9.1.0_LZAP_5.4.1/scinttank_rockgamma_all/lzap_output/*')\n",
    "    with mp.Pool(30) as pool:\n",
    "            rockgamma_data = list(tqdm.tqdm(pool.imap(functools.partial(data_decay),files),total=116))\n",
    "    rockgamma_data=pd.DataFrame(np.concatenate(rockgamma_data,axis=1).T.tolist(),columns=columns)\n",
    "    rockgamma_data=(((rockgamma_data.explode(columns_exp)).reset_index().dropna())).drop(columns='index')\n",
    "    rockgamma_data=rockgamma_data[(rockgamma_data[\"Pulse Area\"] > 5)&(rockgamma_data['Coincidence'] >1)]\n",
    "    \n",
    "    return internals_data,neutron_data,rockgamma_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85e16525-6ce3-4c46-8028-6c1a95e8d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(internals_data,neutron_data,rockgamma_data):\n",
    "    \n",
    "    Th232_chain_tag=['Th232','Ra228','Ac228','Th228','Ra224','Rn220',\n",
    "             'Po216','Po212','Bi212','Pb212','Pb208','Ti208']\n",
    "\n",
    "    U238_chain_tag=['U238','Th234','Pa234','U234','Th230','Ra226',\n",
    "                'Rn222','Po218','Pb214','At218','Bi214','Ti210','Po214',\n",
    "                'Pb210','Hg206','Bi210','Ti206','Po210','Pb206']\n",
    "\n",
    "    electrons_tag=['Th234','Pa234','Bi214','Ti210','Pb210','Bi210',\n",
    "           'Ti206','Ra228','Ac228','Pb212','Bi212','Ti208']\n",
    "\n",
    "    alphas_tag=['U238','U234','Th230','Ra226','Rn222','Po218','At218',\n",
    "        'Bi214','Po214','Pb210','Bi210','Po210','Th232','Th228',\n",
    "        'Ra224','Rn220','Po216','Bi212','Po212']\n",
    "\n",
    "\n",
    "    Th232_chain=internals_data[internals_data['tag'].isin(Th232_chain_tag)]\n",
    "    U238_chain=internals_data[internals_data['tag'].isin(U238_chain_tag)]\n",
    "    U238_Th232_chain=pd.concat([Th232_chain,U238_chain])\n",
    "    reminder=(pd.DataFrame(internals_data).merge(pd.DataFrame(U238_Th232_chain), how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(columns=['_merge']) \n",
    "    reminder=reminder[reminder['tag'] != \"Gd152\"]\n",
    "    U238_chain=U238_chain.drop(columns=[\"tag\"])\n",
    "    U238_chain['tag']='U238'\n",
    "    \n",
    "    Th232_chain=Th232_chain.drop(columns=[\"tag\"])\n",
    "    Th232_chain['tag']='Th232'\n",
    "\n",
    "    electrons=internals_data[internals_data['tag'].isin(electrons_tag)]\n",
    "    alphas=internals_data[internals_data['tag'].isin(alphas_tag)]\n",
    "    electons_alphas=pd.concat([electrons,alphas])\n",
    "    reminder_type=(pd.DataFrame(internals_data).merge(pd.DataFrame(electons_alphas), how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(columns=['_merge']) \n",
    "    reminder_type=reminder_type[reminder_type['tag'] != \"Gd152\"]\n",
    "    electrons=electrons.drop(columns=[\"tag\"])\n",
    "    alphas=alphas.drop(columns=[\"tag\"])\n",
    "    electrons['tag']='electron'\n",
    "    alphas['tag']='alpha'\n",
    "    return Th232_chain,U238_chain,reminder, electrons, alphas,reminder_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c6b688e-a75e-4d1c-b3b6-8b56c80a190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OldData():\n",
    "    \"\"\"\n",
    "    function to call and concatenate all the data\n",
    "    \"\"\"\n",
    "    columns={'Pulse Area' : [], 'Coincidence' : [], 'Peak Time' : [],'Peak Amp' : [], '25% time' : [], '50% time' : [], '75% time' : [], 'Pulse Time' : [], 'time/area' : []}\n",
    "    \n",
    "    bi212_files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.11_DER_9.1.0_LZAP_5.2.8/bi212/lzap_output/*')\n",
    "    bi212_data = [f for f in bi212_files if 'mctruth' not in f]\n",
    "    \n",
    "    po212_files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.11_DER_9.1.0_LZAP_5.2.8/po212/lzap_output/*')\n",
    "    po212_data = [f for f in po212_files if 'mctruth' not in f]\n",
    "    \n",
    "    neutron_files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.11_DER_9.1.0_LZAP_5.2.8/gdls_neutrons/lzap_output/*')\n",
    "    neutron_data = [f for f in neutron_files if 'mctruth' not in f]\n",
    "    \n",
    "    na22_files = glob.glob('/hdfs/user/ak18773/od_simulations/BACCARAT_6.2.11_DER_9.1.0_LZAP_5.2.8/na22_z700/lzap_output/*')\n",
    "    na22_data = [f for f in na22_files if 'mctruth' not in f]\n",
    "    \n",
    "\n",
    "    \n",
    "    with mp.Pool(30) as pool:\n",
    "        bi212 = list(tqdm.tqdm(pool.imap(functools.partial(old_decay),bi212_data),total=200))\n",
    "    bi212=pd.DataFrame(np.concatenate(bi212,axis=1).T.tolist(),columns=columns)\n",
    "    bi212=Data_bi212[Data_bi212[\"Pulse Area\"] > 10]\n",
    "    bi212=Data_bi212[Data_bi212[\"Coincidence\"] > 5]\n",
    "    \n",
    "    with mp.Pool(30) as pool:\n",
    "        po212 = list(tqdm.tqdm(pool.imap(functools.partial(old_decay),po212_data),total=200))\n",
    "    po212=pd.DataFrame(np.concatenate(po212,axis=1).T.tolist(),columns=columns)\n",
    "    po212=Data_po212[Data_po212[\"Pulse Area\"] > 10]\n",
    "    po212=Data_po212[Data_po212[\"Coincidence\"] > 5]\n",
    "   \n",
    "    with mp.Pool(30) as pool:\n",
    "        neutron = list(tqdm.tqdm(pool.imap(functools.partial(old_decay),neutron_data),total=464))\n",
    "    neutron=pd.DataFrame(np.concatenate(neutron,axis=1).T.tolist(),columns=columns)\n",
    "    neutron=Data_neutron[Data_neutron[\"Pulse Area\"] > 10]\n",
    "    neutron=Data_neutron[Data_neutron[\"Coincidence\"] > 5]\n",
    "    \n",
    "    with mp.Pool(30) as pool:\n",
    "        na22 = list(tqdm.tqdm(pool.imap(functools.partial(old_decay),na22_data),total=200))\n",
    "    na22=pd.DataFrame(np.concatenate(na22,axis=1).T.tolist(),columns=columns)\n",
    "    na22=Data_na22[Data_na22[\"Pulse Area\"] > 10]\n",
    "    na22=Data_na22[Data_na22[\"Coincidence\"] > 5]\n",
    "    \n",
    "    \n",
    "    \n",
    "    bi212[\"tag\"]=\"bi212\"\n",
    "    po212_tag[\"tag\"]=\"po212\"\n",
    "    neutron_tag[\"tag\"]=\"neutron\"\n",
    "    na22_tag[\"tag\"]=\"na22\"\n",
    "    dataframes=[bi212,po212,neutron,na22]\n",
    "    Data=pd.concat(dataframes)\n",
    "    \n",
    "    \n",
    "    return dataframes,Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44183e5a-0988-4c0e-bd81-8e84841e8dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75c42d1f-a122-412e-8b55-495ddefa9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls and plots data\n",
    "def plot(Data1,Data2,Data3,Data4,Data,label1,label2,label3,label4):\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "    axes[0,0].scatter(Data1['Pulse Area'],Data2['Coincidence'],label=label1,alpha=0.2)\n",
    "\n",
    "    axes[0,0].set_xlabel(\"Area\")\n",
    "    axes[0,0].set_ylabel(\"coincidence\")\n",
    "    axes[0,0].legend(loc='lower right')\n",
    "    axes[0,0].set_title(\"pulse area against coincidence\")\n",
    "\n",
    "\n",
    "\n",
    "    axes[0,1].scatter(Data2['Pulse Area'],Data2['Coincidence'],label=label2,alpha=0.2,color=\"orange\")\n",
    "\n",
    "    axes[0,1].set_xlabel(\"Area\")\n",
    "    axes[0,1].set_ylabel(\"coincidence\")\n",
    "    axes[0,1].legend(loc='lower right')\n",
    "    axes[0,1].set_title(\"pulse area against coincidence\")\n",
    "\n",
    "\n",
    "    axes[1,0].scatter(Data3['Pulse Area'],Data3['Coincidence'],label=label3,alpha=0.2,color=\"r\")\n",
    "    axes[1,0].set_xlabel(\"Area\")\n",
    "    axes[1,0].set_ylabel(\"coincidence\")\n",
    "    axes[1,0].legend(loc='lower right')\n",
    "    axes[1,0].set_title(\"pulse area against coincidence\")\n",
    "\n",
    "    axes[1,1].scatter(Data4['Pulse Area'],Data4['Coincidence'],label=label4,alpha=0.2)\n",
    "    axes[1,1].set_xlabel(\"Pulse Area\")\n",
    "    axes[1,1].set_ylabel(\"Coincidence\")\n",
    "    axes[1,1].legend(loc='lower right')\n",
    "    axes[1,1].set_title(\"area against coincidence\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "    axes[0,0].scatter(Data1['Pulse Area'],Data1['Peak Amp'],label=label1,alpha=0.3)\n",
    "    axes[0,0].scatter(Data2['Pulse Area'],Data2['Peak Amp'],label=label2,alpha=0.3)\n",
    "    axes[0,0].scatter(Data3['Pulse Area'],Data3['Peak Amp'],label=label3,alpha=0.3)\n",
    "    axes[0,0].scatter(Data4['Pulse Area'],Data4['Peak Amp'],label=label4,alpha=0.3)\n",
    "    axes[0,0].set_xlabel(\"Pulse area\")\n",
    "    axes[0,0].set_ylabel(\"peak current\")\n",
    "    axes[0,0].legend(loc='upper right')\n",
    "    axes[0,0].set_title(\"pulse area vs peak current\")\n",
    "\n",
    "\n",
    "    axes[0,1].scatter(Data1['Coincidence'],Data1['Peak Amp'],label=label1,alpha=0.2)\n",
    "    axes[0,1].scatter(Data2['Coincidence'],Data2['Peak Amp'],label=label2,alpha=0.2)\n",
    "    axes[0,1].scatter(Data3['Coincidence'],Data3['Peak Amp'],label=label3,alpha=0.2)\n",
    "    axes[0,1].scatter(Data4['Coincidence'],Data4['Peak Amp'],label=label4,alpha=0.2)\n",
    "    axes[0,1].set_xlabel(\"Coincidence\")\n",
    "    axes[0,1].set_ylabel(\"peak current\")\n",
    "    axes[0,1].legend(loc='upper right')\n",
    "    axes[0,1].set_title(\"coincidence vs peak current\")\n",
    "\n",
    "    axes[1,0].hist(Data1['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500], label=label1)\n",
    "    axes[1,0].hist(Data2['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label2)\n",
    "    axes[1,0].hist(Data3['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label3)\n",
    "    axes[1,0].hist(Data4['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label4)\n",
    "    axes[1,0].set_xlabel(\"Pulse Area\")\n",
    "    axes[1,0].legend(loc='upper right')\n",
    "    axes[1,0].set_title(\"Pulse Area\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    axes[1,1].hist(Data1['Pulse Time'], alpha = 0.7,bins=55,label=label1)\n",
    "    axes[1,1].hist(Data2['Pulse Time'], alpha = 0.7,bins=55,label=label2)\n",
    "    axes[1,1].hist(Data3['Pulse Time'], alpha = 0.7,bins=55,label=label3)\n",
    "    axes[1,1].hist(Data4['Pulse Time'], alpha = 0.7,bins=55,label=label4)\n",
    "    axes[1,1].set_xlabel(\"Pulse Time\")\n",
    "    axes[1,1].legend(loc='upper right')\n",
    "    axes[1,1].set_title(\"Pulse Time\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes[0,0].hist(Data1['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500], label=label1)\n",
    "    axes[0,0].hist(Data2['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label2)\n",
    "    axes[0,0].hist(Data3['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label3)\n",
    "    axes[0,0].hist(Data4['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label=label4)\n",
    "\n",
    "    axes[0,1].hist(Data1['Coincidence'],histtype='step',bins=100,stacked=True ,density=True, label=label1)\n",
    "    axes[0,1].hist(Data2['Coincidence'],histtype='step',bins=100,stacked=True ,density=True,label=label2)\n",
    "    axes[0,1].hist(Data3['Coincidence'],histtype='step',bins=100,stacked=True ,density=True,label=label3)\n",
    "    axes[0,1].hist(Data4['Coincidence'],histtype='step',bins=100,stacked=True ,density=True,label=label4)\n",
    "                         \n",
    "    axes[0,2].hist(Data1['Peak Time'],bins=30,stacked=True ,density=True,range=[0,200], label=label1)\n",
    "    axes[0,2].hist(Data2['Peak Time'],bins=30,stacked=True ,density=True,range=[0,200],label=label2)\n",
    "    axes[0,2].hist(Data3['Peak Time'],bins=30,stacked=True ,density=True,range=[0,200],label=label3)\n",
    "    axes[0,2].hist(Data4['Peak Time'],bins=30,stacked=True ,density=True,range=[0,200],label=label4)\n",
    "                         \n",
    "                         \n",
    "    axes[1,0].hist(Data1['Peak Amp'],histtype='step',bins=200,stacked=True ,density=True, range=[0,8],label=label1)\n",
    "    axes[1,0].hist(Data2['Peak Amp'],histtype='step',bins=200,stacked=True ,density=True,range=[0,8],label=label2)\n",
    "    axes[1,0].hist(Data3['Peak Amp'],histtype='step',bins=200,stacked=True ,density=True,range=[0,8],label=label3)\n",
    "    axes[1,0].hist(Data4['Peak Amp'],histtype='step',bins=200,stacked=True ,density=True,range=[0,8],label=label4)\n",
    "                         \n",
    "                         \n",
    "    axes[1,1].hist(Data1['25% time'],bins=30,stacked=True ,density=True, range=[0,200],label=label1)\n",
    "    axes[1,1].hist(Data2['25% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label2)\n",
    "    axes[1,1].hist(Data3['25% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label3)\n",
    "    axes[1,1].hist(Data4['25% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label4)\n",
    "    \n",
    "    axes[1,2].hist(Data1['Pulse Time'],bins=100,stacked=True ,density=True,label=label1)\n",
    "    axes[1,2].hist(Data2['Pulse Time'],bins=100,stacked=True ,density=True,label=label2)\n",
    "    axes[1,2].hist(Data3['Pulse Time'],bins=100,stacked=True ,density=True,label=label3)\n",
    "    axes[1,2].hist(Data4['Pulse Time'],bins=100,stacked=True ,density=True,label=label4)\n",
    "                         \n",
    "    axes[2,0].hist(Data1['75% time'],bins=30,stacked=True ,density=True,range=[0,250], label=label1)\n",
    "    axes[2,0].hist(Data2['75% time'],bins=30,stacked=True ,density=True,range=[0,250],label=label2)\n",
    "    axes[2,0].hist(Data3['75% time'],bins=30,stacked=True ,density=True,range=[0,250],label=label3)\n",
    "    axes[2,0].hist(Data4['75% time'],bins=30,stacked=True ,density=True,range=[0,250],label=label4)\n",
    "                         \n",
    "                         \n",
    "    axes[2,1].hist(Data1['50% time'],bins=30,stacked=True ,density=True,range=[0,200], label=label1)\n",
    "    axes[2,1].hist(Data2['50% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label2)\n",
    "    axes[2,1].hist(Data3['50% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label3)\n",
    "    axes[2,1].hist(Data4['50% time'],bins=30,stacked=True ,density=True,range=[0,200],label=label4)\n",
    "\n",
    "    axes[2,2].hist(Data1['time/area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,3], label=label1)\n",
    "    axes[2,2].hist(Data2['time/area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,3],label=label2)\n",
    "    axes[2,2].hist(Data3['time/area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,3],label=label3)\n",
    "    axes[2,2].hist(Data4['time/area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,3],label=label4)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d44f40-679e-48f8-8973-c1eafcb41648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e42494bc-20d8-4026-92c0-f9c24cb842fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(Data_bi212,Data_po212,Data_neutron,Data_na22,Data_notag,Data_withtag):\n",
    "    \n",
    "    columns=[\"Pulse Area\",\"Coincidence\", \"Peak Time\", \"Peak Amp\", \"25% time\",'Pulse Time', \"75% time\", \"50% time\",\"time/area\"]\n",
    "################################ORIGINAL_CUT###########################################   \n",
    "    neutron_data_guess1=Data_notag[(Data_notag[\"Pulse Area\"] > 410) ]\n",
    "    bi212_data_guess=Data_notag[(Data_notag[\"Pulse Area\"] > 250) & (Data_notag[\"Pulse Area\"] < 410)]\n",
    "    po212_data_guess=Data_notag[(Data_notag[\"Pulse Area\"] > 45) & (Data_notag[\"Pulse Area\"] < 125)]\n",
    "    na22_data_guess1=Data_notag[((Data_notag[\"Pulse Area\"] > 0) & (Data_notag[\"Pulse Area\"] < 45))  &((Data_notag['Coincidence'] <100) &(Data_notag['Coincidence'] >0)) & (Data_notag['Peak Amp'] <2)]\n",
    "################################GUESS_DATA###########################################\n",
    "    \n",
    "    guess_frames=[bi212_data_guess,po212_data_guess,neutron_data_guess1,na22_data_guess1]\n",
    "    guess_data=pd.concat(guess_frames)\n",
    "    \n",
    "################################MISSING_DATA###########################################  \n",
    "    notag_guess = Data_notag.merge(guess_data.drop_duplicates(), on=columns, how='left', indicator=True)\n",
    "    missing_data=notag_guess[notag_guess[\"_merge\"] == \"left_only\"]\n",
    "    missing_neutron=missing_data[missing_data[\"Pulse Time\"] >400]\n",
    "    missing_na22=missing_data[missing_data[\"Pulse Time\"] <= 400]\n",
    "    neutron_df=[pd.DataFrame(neutron_data_guess1),missing_neutron]\n",
    "    na22_df=[pd.DataFrame(na22_data_guess1),missing_na22]\n",
    "    neutron_data_guess=(pd.concat(neutron_df)).drop(columns=[\"_merge\"])\n",
    "    na22_data_guess=(pd.concat(na22_df)).drop(columns=[\"_merge\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "################################PURITY_OF_DATA###########################################    \n",
    "\n",
    "    neutron_data_purity=Data_neutron.merge(neutron_data_guess, how='inner', indicator=False)\n",
    "    \n",
    "    bi212_data_purity=Data_bi212.merge(bi212_data_guess, how='inner', indicator=False)\n",
    "    \n",
    "    po212_data_purity=Data_po212.merge(po212_data_guess, how='inner', indicator=False)\n",
    "    \n",
    "    na22_data_purity=Data_na22.merge(na22_data_guess, how='inner', indicator=False)\n",
    "    \n",
    "################################METRICS###########################################\n",
    "    neutron_captured=((len(neutron_data_purity)))*100/len(Data_neutron)\n",
    "    neutron_accuracy=(len(neutron_data_purity)/len(neutron_data_guess))*100\n",
    "    \n",
    "    bi212_captured=len(bi212_data_purity)*100/len(Data_bi212)\n",
    "    bi212_accuracy=(len(bi212_data_purity)/len(bi212_data_guess))*100\n",
    "    \n",
    "    po212_captured=len(po212_data_purity)*100/len(Data_po212)\n",
    "    po212_accuracy=(len(po212_data_purity)/len(po212_data_guess))*100\n",
    "    \n",
    "    na22_captured=((len(na22_data_purity)))*100/len(Data_na22)\n",
    "    na22_accuracy=(len(na22_data_purity)/len(na22_data_guess))*100\n",
    "    \n",
    "################################RECOMBINATION_AND_OUTPUT###########################################   \n",
    "    \n",
    "    guess_info=[(bi212_captured,bi212_accuracy),(po212_captured,po212_accuracy),(neutron_captured,neutron_accuracy),(na22_captured,na22_accuracy)]\n",
    "    \n",
    "    guess_frames=[bi212_data_guess,po212_data_guess,neutron_data_guess,na22_data_guess]\n",
    "    \n",
    "    print(\"cut isolates {:1.2f}% of neutron data. {:1.2f}% of the selected data are neutrons.\".format(neutron_captured,neutron_accuracy))\n",
    "    print(\"cut isolates {:1.2f}% of bi212 data. {:1.2f}% of the selected data is bi212.\".format(bi212_captured,bi212_accuracy))\n",
    "    print(\"cut isolates {:1.2f}% of po212 data. {:1.2f}% of the selected data is po212.\".format(po212_captured,po212_accuracy))\n",
    "    print(\"cut isolates {:1.2f}% of na22 data. {:1.2f}% of the selected data is na22.\".format(na22_captured,na22_accuracy))\n",
    "    guess_data=pd.concat(guess_frames)\n",
    "    data_captured=(len(guess_data)/len(Data_notag))*100\n",
    "    print(f\" {data_captured}% of the data has been captured\")\n",
    "    \n",
    "    return guess_data,guess_frames,guess_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4cdda619-ae70-4420-a8e2-9550d069804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_metrics(data_guess,Data_real,Data_withtag,decay):\n",
    "            not_guess_data = (Data_withtag.merge(data_guess, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(columns=['_merge'])   \n",
    "            \n",
    "        \n",
    "            tp=len(data_guess[data_guess['tag'] == decay ])\n",
    "            tn=len(not_guess_data[not_guess_data['tag'] != decay])\n",
    "            fp=len(data_guess[data_guess['tag'] != decay ])\n",
    "            fn=len(not_guess_data[not_guess_data['tag'] == decay])\n",
    "        \n",
    "        \n",
    "            \n",
    "            accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "          \n",
    "            if (tp+fn) == 0:\n",
    "                recall=0 \n",
    "            else:\n",
    "                recall=(tp)/(tp+fn)\n",
    "\n",
    "            precision=(tp)/(tp+fp)\n",
    "            if (recall+precision) == 0:\n",
    "                F=0\n",
    "            else:\n",
    "                F=(2*recall*precision)/(recall+precision)\n",
    "            if (tn+fp) ==0:\n",
    "                specificity=0\n",
    "            else:\n",
    "                specificity=(tn)/(tn+fp)\n",
    "            return accuracy,recall,precision,F,specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5bb0cc49-2799-424b-b14a-20203dfa8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_cut(start_point,Data_withtag,decay):\n",
    "    area_range_max=np.arange(start_point,500,5)\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    recall_list=[]\n",
    "    precision_list=[]\n",
    "    F_list=[]\n",
    "    specificity_list=[]\n",
    "    minval=[]\n",
    "    maxval=[]\n",
    "    for end_point in area_range_max:\n",
    "        \n",
    "        data_guess=Data_withtag[(Data_withtag[\"Pulse Area\"] > start_point) & (Data_withtag[\"Pulse Area\"] < end_point)]    \n",
    "        \n",
    "        \n",
    "        not_guess_data = (Data_withtag.merge(data_guess, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']).drop(columns=['_merge'])   \n",
    "           \n",
    "        \n",
    "        tp=len(data_guess[data_guess['tag'] == decay ])\n",
    "        tn=len(not_guess_data[not_guess_data['tag'] != decay])\n",
    "        fp=len(data_guess[data_guess['tag'] != decay ])\n",
    "        fn=len(not_guess_data[not_guess_data['tag'] == decay])\n",
    "        \n",
    "        \n",
    "            \n",
    "        accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
    "          \n",
    "        if (tp+fn) == 0:\n",
    "            recall=0 \n",
    "        else:\n",
    "            recall=(tp)/(tp+fn)\n",
    "        if (tp+fp) ==0:\n",
    "            precision =0\n",
    "        else:\n",
    "            precision=(tp)/(tp+fp)\n",
    "        if (recall+precision) ==0:\n",
    "            F=0\n",
    "        else:\n",
    "            F=(2*recall*precision)/(recall+precision)\n",
    "        if (tn+fp) ==0:\n",
    "            specificity=0\n",
    "        else:\n",
    "            specificity=(tn)/(tn+fp)\n",
    "        accuracy_list.append(accuracy)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n",
    "        F_list.append(F)\n",
    "        specificity_list.append(specificity)\n",
    "        minval.append(start_point)\n",
    "        maxval.append(end_point)\n",
    "    return [minval,maxval,accuracy_list,recall_list,precision_list,F_list,specificity_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c0a286c-f713-4630-b545-c38edd9caa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_cut(set1,set2,set3,set4,combined,decay1,decay2,decay3,decay4):\n",
    "##########################################AUTOMATEDCUT#################################################\n",
    "    columns=[\"Pulse Area\",\"Coincidence\", \"Peak Time\", \"Peak Amp\", \"25% time\",'Pulse Time', \"75% time\", \"50% time\",\"time/area\"]\n",
    "    info_columns={'minval' : [],'maxval' : [],'accuracy' : [], 'recall' : [], 'precision' : [], 'F1 score' : [], 'specificity' :[]}\n",
    "    \n",
    "    area_range_min=np.arange(0,500,5)\n",
    "    \n",
    "    with mp.Pool(40) as pool:\n",
    "         set1_data=list(tqdm.tqdm(pool.imap(functools.partial(area_cut,Data_withtag=combined,decay=decay1),area_range_min),total=100))\n",
    "    info_set1=pd.DataFrame(np.concatenate(set1_data,axis=1).T.tolist(),columns=info_columns)\n",
    "    max_set1=info_set1[info_set1['F1 score'] == info_set1['F1 score'].max()]       \n",
    "    \n",
    "    with mp.Pool(40) as pool:\n",
    "         set2_data=list(tqdm.tqdm(pool.imap(functools.partial(area_cut,Data_withtag=combined,decay=decay2),area_range_min),total=100))\n",
    "    info_set2=pd.DataFrame(np.concatenate(set2_data,axis=1).T.tolist(),columns=info_columns)\n",
    "    \n",
    "    max_set2=info_set2[info_set2['F1 score'] == info_set2['F1 score'].max()]\n",
    "    \n",
    "    \n",
    "    with mp.Pool(40) as pool:\n",
    "         set3_data=list(tqdm.tqdm(pool.imap(functools.partial(area_cut,Data_withtag=combined,decay=decay3),area_range_min),total=100))\n",
    "    info_set3=pd.DataFrame(np.concatenate(set3_data,axis=1).T.tolist(),columns=info_columns)       \n",
    "    max_set3=info_set3[info_set3['F1 score'] == info_set3['F1 score'].max()]\n",
    "    \n",
    "    \n",
    "    with mp.Pool(40) as pool:\n",
    "         set4_data=list(tqdm.tqdm(pool.imap(functools.partial(area_cut,Data_withtag=combined,decay=decay4),area_range_min),total=100))\n",
    "    info_set4=pd.DataFrame(np.concatenate(set4_data,axis=1).T.tolist(),columns=info_columns)\n",
    "    \n",
    "    max_set4=info_set4[info_set4['F1 score'] == info_set4['F1 score'].max()]       \n",
    "    \n",
    "    info=[info_set1,info_set2,info_set3,info_set4]\n",
    "\n",
    "############################################APPLYING-CUT##########################################################    \n",
    "   \n",
    "    set1_data_guess=combined[(combined[\"Pulse Area\"] > max_set1['minval'].max()) & (combined[\"Pulse Area\"] < max_set1['maxval'].max())]\n",
    "    set2_data_guess=combined[(combined[\"Pulse Area\"] > max_set2['minval'].max()) & (combined[\"Pulse Area\"] < max_set2['maxval'].max())]\n",
    "    set3_data_guess=combined[(combined[\"Pulse Area\"] > max_set3['minval'].max()) & (combined[\"Pulse Area\"] < max_set3['maxval'].max())]\n",
    "    set4_data_guess=combined[((combined[\"Pulse Area\"] > max_set4['minval'].max()) & (combined[\"Pulse Area\"] < max_set4['maxval'].max()))]\n",
    "    \n",
    "    \n",
    "    guess_frames=[set1_data_guess,set2_data_guess,set3_data_guess,set4_data_guess]\n",
    "    guess_data=pd.concat(guess_frames)\n",
    "\n",
    "########################REDEFINE-METRICS#########################################\n",
    "    set1_accuracy,set1_recall,set1_precision,set1_F,set1_specificity=cut_metrics(set1_data_guess,set1,combined,decay1)\n",
    "    set2_accuracy,set2_recall,set2_precision,set2_F,set2_specificity=cut_metrics(set2_data_guess,set2,combined,decay2)\n",
    "    set3_accuracy,set3_recall,set3_precision,set3_F,set3_specificity=cut_metrics(set3_data_guess,set3,combined,decay3)\n",
    "    set4_accuracy,set4_recall,set4_precision,set4_F,set4_specificity=cut_metrics(set4_data_guess,set4,combined,decay4)\n",
    "    data=[set1_data_guess,set2_data_guess,set3_data_guess,set4_data_guess]\n",
    "########################################################################################\n",
    "    columns={'sample' : [], 'accuracy' : [], 'recall' : [], 'precision' : [], 'F1 score' : [], 'specificity' : []}\n",
    "    metrics=pd.DataFrame(columns=columns)\n",
    "    metrics['sample']=[decay1,decay2,decay3,decay4]\n",
    "    metrics['accuracy']=[set1_accuracy,set2_accuracy,set3_accuracy,set4_accuracy]\n",
    "    metrics['recall']=[set1_recall,set2_recall,set3_recall,set4_recall]\n",
    "    metrics['precision']=[set1_precision,set2_precision,set3_precision,set4_precision]\n",
    "    metrics['F1 score']=[set1_F,set2_F,set3_F,set4_F]\n",
    "    metrics['specificity']=[set1_specificity,set2_specificity,set3_specificity,set4_specificity]\n",
    "    print(metrics)\n",
    "###############################################OUTPUT-STATEMENTS#####################################\n",
    "\n",
    "\n",
    "    \n",
    "    return metrics,data,info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fad02f9b-c6dd-4c2e-8c93-20d21d6271d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classifier(output_bias):\n",
    "    \n",
    "    output_bias=tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(9,input_dim=9, activation='relu'),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(36, activation=\"relu\"),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\",bias_initializer=output_bias)])\n",
    "    \n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',  metrics=['AUC',\"binary_accuracy\"], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def multiclassifier():\n",
    "    \n",
    "    output_bias=tf.keras.initializers.Constant()\n",
    "\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(9,input_dim=9, activation='relu'),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(36, activation=\"relu\"),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(18, activation=\"relu\"),\n",
    "    keras.layers.Dense(4, activation=\"softmax\")])\n",
    "    \n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',  metrics=['AUC',\"categorical_accuracy\"], optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(Data_withtag,sample1,sample2,dataset):\n",
    "    if dataset == 1:\n",
    "        features=Data_withtag[(Data_withtag['tag'] == sample1) | (Data_withtag['tag'] == sample2)]\n",
    "        labels=Data_withtag[(Data_withtag['tag'] == sample1) | (Data_withtag['tag'] == sample2)]\n",
    "        features=(features.iloc[:,0:9]).apply(pd.to_numeric)\n",
    "    if dataset ==2:\n",
    "        print(\"nope\")\n",
    "    features=tf.keras.utils.normalize(features).squeeze()\n",
    "    \n",
    "    labels=labels.iloc[:,-1]\n",
    "    labels = pd.get_dummies(data = labels, columns=[sample1],drop_first=True)\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "    labels_train=np.asarray(labels_train).astype('float32').reshape((-1,1))\n",
    "    labels_test=np.asarray(labels_test).astype('float32').reshape((-1,1))\n",
    "    return features_train,features_test,labels_train,labels_test\n",
    "\n",
    "def confusion_metrics(confusion_matrix,sample):\n",
    "    tp=confusion_matrix[0,0]\n",
    "    fn=confusion_matrix[0,1]\n",
    "    fp=confusion_matrix[1,0]\n",
    "    tn=confusion_matrix[1,1]\n",
    "    \n",
    "    accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "    recall=(tp)/(tp+fn)\n",
    "    precision=(tp)/(tp+fp)\n",
    "    F1=(2*recall*precision)/(recall+precision)\n",
    "    specificity=(tn)/(tn+fp)\n",
    "\n",
    "    \n",
    "\n",
    "    return sample,accuracy,recall,precision,F1,specificity\n",
    "\n",
    "def discriminator(probability):\n",
    "    prediction=np.where(probability > 0.5, 1, 0)\n",
    "    return prediction\n",
    "\n",
    "def binary_run(Data_withtag,sample,sample1,sample2):\n",
    "    \n",
    "    \n",
    "    stop = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=40)\n",
    "    features_train,features_test,labels_train,labels_test=preprocess(Data_withtag,sample1,sample2,dataset=1)\n",
    "    train_label_df=pd.DataFrame(labels_train,columns=['tag'])\n",
    "    pos=len(train_label_df[train_label_df['tag']==1])\n",
    "    neg=len(train_label_df[train_label_df['tag']==0])\n",
    "    total=len(train_label_df['tag'])\n",
    "    initial_bias = np.log([pos/neg])\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    \n",
    "    model=binary_classifier(output_bias=initial_bias)\n",
    "\n",
    "    model.summary()\n",
    "    history=model.fit(features_train, labels_train, epochs=75, batch_size=256, verbose=1,validation_split=0.2, callbacks=[stop],class_weight=class_weight)\n",
    "\n",
    "    proba = model.predict(features_test).ravel()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels_test, proba)\n",
    "    precision, recall,recall_thresholds = precision_recall_curve(labels_test, proba)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    predictions = discriminator(proba)\n",
    "    columns={'FPR' : [], 'TPR' : [],'auc-roc' : []}\n",
    "    pr_columns={'precision' : [], 'recall' : [],'auc-pr' : []}\n",
    "    roc_metrics=pd.DataFrame(columns=columns)\n",
    "    pr_metrics=pd.DataFrame(columns=pr_columns)\n",
    "    roc_metrics['FPR']=fpr\n",
    "    roc_metrics['TPR']=tpr\n",
    "    roc_metrics['thresholds']=thresholds\n",
    "    roc_metrics['auc-roc']=auc_roc\n",
    "    pr_metrics['precision']=precision\n",
    "    pr_metrics['recall']=recall\n",
    "    additional=pd.DataFrame({'thresholds': recall_thresholds})\n",
    "    \n",
    "    pr_metrics['auc-pr']=auc_pr\n",
    "    pr_metrics=pd.concat([pr_metrics,additional], axis=1)\n",
    "    \n",
    "    confusion=confusion_matrix(labels_test, predictions)\n",
    "    metrics=confusion_metrics(confusion,sample)\n",
    "    \n",
    "    \n",
    "    return metrics,roc_metrics,pr_metrics,history,proba\n",
    "\n",
    "def multiclass(decay_type):\n",
    "\n",
    "\n",
    "    oversample = SMOTE()\n",
    "    stop = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=200)\n",
    "    features=(decay_type.iloc[:,0:9]).apply(pd.to_numeric)\n",
    "    features=tf.keras.utils.normalize(features).squeeze()\n",
    "    labels=decay_type.iloc[:,-1]\n",
    "    labels = pd.get_dummies(data = labels)\n",
    "    features, labels= oversample.fit_resample(np.asarray(features), np.asarray(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "    labels_train=np.asarray(labels_train).astype('float32')\n",
    "    labels_test=np.asarray(labels_test).astype('float32')\n",
    "\n",
    "    model=multiclassifier()\n",
    "\n",
    "    model.summary()\n",
    "    history=model.fit(features_train, labels_train, epochs=200, batch_size=512, verbose=1,validation_split=0.2, callbacks=[stop])\n",
    "    proba = model.predict(features_test)\n",
    "    return history, labels_test ,proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01190-1750-45fc-aec3-649e5ed04343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                       | 90/3000 [00:04<01:20, 36.14it/s]"
     ]
    }
   ],
   "source": [
    "#dataframes,data=OldData()\n",
    "\n",
    "internals_data,neutron_data,rockgamma_data=data()\n",
    "Th232_chain,U238_chain,reminder, electrons, alphas,reminder_type=separate(internals_data,neutron_data,rockgamma_data)\n",
    "decay_type=pd.concat([electrons,alphas,neutron_data,rockgamma_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775c3f9-a8a7-41d6-a6fb-02dbdbc76df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data_bi212=dataframes[0]\n",
    "#Data_po212=dataframes[1]\n",
    "#Data_neutron=dataframes[2]\n",
    "#Data_na22=dataframes[3]\n",
    "#plot(Data_bi212,Data_po212,Data_neutron,Data_na22,data,'bi212','po212','neutron','na22')\n",
    "#guess_data,guess_frames,guess_info=cut(Data_bi212,Data_po212,Data_neutron,Data_na22,Data_rockgamma,Data_notag,Data_withtag)\n",
    "#metrics,data,info=auto_cut(Data_bi212,Data_po212,Data_neutron,Data_na22,Data_withtag)\n",
    "#metrics,data,info=auto_cut(electrons,alphas,neutron_data,rockgamma_data,decay_type,'electron','alpha','neutron','RockGamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272486fc-6101-42ab-94d9-e621be6ef139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8494750-74e4-4ae7-8fc4-7b6968b3a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bi212_data=data[0]\n",
    "#po212_data=data[1]\n",
    "#neutron_data=data[2]\n",
    "#na22_data=data[3]\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.hist(bi212_data['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label='electrons')\n",
    "#plt.hist(po212_data['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label='alpha')\n",
    "#plt.hist(neutron_data['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label='neutrons')\n",
    "#plt.hist(na22_data['Pulse Area'],histtype='step',bins=200,stacked=True ,density=True,range=[0,500],label='gamma')\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#metrics['method']='cut'\n",
    "#print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac3e2f-ee8a-4e3f-a10c-282c5a587fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_bi212_po212,roc_metrics_bi212_po212,pr_metrics_bi212_po212,history_bi212_po212,probs_bi212_po212=binary_run(Data_withtag,\"bi212-po212\",\"bi212\",\"po212\")\n",
    "#metrics_neutrons_na22,roc_metrics_neutrons_na22,pr_metrics_neutrons_na22,history_neutrons_na22,proba_neutrons_na22=binary_run(Data_withtag,\"neutrons-na22\",\"neutron\",\"na22\")\n",
    "#metrics_bi212_neutrons,roc_metrics_bi212_neutrons,pr_metrics_bi212_neutrons,history_bi212_neutrons,proba_bi212_neutrons=binary_run(Data_withtag,\"bi212-neutrons\",\"bi212\",\"neutron\")\n",
    "#metrics_po212_na22,roc_metrics_po212_na22,pr_metrics_po212_na22,history_po212_na22,probs_po212_na22=binary_run(Data_withtag,\"po212_na22\",\"po212\",\"na22\")\n",
    "\n",
    "#NN_metrics=(pd.concat([metrics_bi212_po212,metrics_neutrons_na22,metrics_bi212_neutrons,metrics_po212_na22])).set_index('sample')\n",
    "\n",
    "\n",
    "\n",
    "#metrics_electron_alpha,roc_metrics_electron_alpha,pr_metrics_electron_alpha,history_electron_alpha,proba_electron_alpha=binary_run(decay_type,\"electrons vs alphas\",\"electron\",\"alpha\")\n",
    "#metrics_gamma_neutron,roc_metrics_gamma_neutron,pr_metrics_gamma_neutron,history_gamma_neutron,proba_gamma_neutron=binary_run(decay_type,\"rockgamma vs neutrons\",\"RockGamma\",\"neutron\")\n",
    "#metrics_gamma_electron,roc_metrics_gamma_electron,pr_metrics_gamma_electron,history_gamma_electron,proba_gamma_electron=binary_run(decay_type,\"rockgamma vs electons\",\"RockGamma\",\"electron\")\n",
    "#metrics_electron_neutron,roc_metrics_electron_neutron,pr_metrics_electron_neutron,history_electron_neutron,proba_electron_neutron=binary_run(decay_type,\"electron vs neutrons\",\"electron\",\"neutron\")\n",
    "#metrics_chains,roc_metrics_chains,pr_metrics_chains,history_chains,proba_chains=binary_run(chains,\"electron vs neutrons\",\"U238\",\"Th232\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ed823-4d8d-40bc-aecf-91f4c588d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57765f67-8fbd-41e9-96a6-2307f5ed2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "history, labels_test,proba=multiclass(electrons,alphas,neutron_data,rockgamma_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0803cdd-8877-4716-9c7f-eda4247b79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "thresh ={}\n",
    "prec={}\n",
    "recall={}\n",
    "recall_thresh={}\n",
    "confusion_list=[]\n",
    "NN_metrics_list=[]\n",
    "F1={}\n",
    "n_class = 4\n",
    "sample=[\"electron\",\"alpha\",'Gamma','neutron']\n",
    "for i in range(n_class):    \n",
    "    fpr[i], tpr[i], thresh[i] = roc_curve(labels_test[:,i], proba[:,i], pos_label=1)\n",
    "    prec[i], recall[i],recall_thresh[i] = precision_recall_curve(labels_test[:,i], proba[:,i], pos_label=1)\n",
    "    predictions = discriminator(proba[:,i])\n",
    "    confusion=confusion_matrix(labels_test[:,i], predictions)\n",
    "    NN_metrics_list.append(confusion_metrics(confusion,sample[i]))\n",
    "    F1[i]=(2*recall[i]*prec[i])/(recall[i]+prec[i])\n",
    "\n",
    "F1[0]=F1[0][:-1]\n",
    "F1[1]=F1[1][:-1]\n",
    "F1[2]=F1[2][:-1]\n",
    "F1[3]=F1[3][:-1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Electrons (area = {:.3f})'.format(auc(fpr[0],tpr[0])))\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Alphas (area = {:.3f})'.format(auc(fpr[1],tpr[1])))\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Gamma (area = {:.3f})'.format(auc(fpr[2],tpr[2])))\n",
    "plt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='Neutrons (area = {:.3f})'.format(auc(fpr[3],tpr[3])))\n",
    "plt.plot([0, 1], [0, 1],linestyle='dashdot',color='red', label='No classifier')\n",
    "plt.title('Multiclass ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(recall[0], prec[0],color='orange', label='Electrons (area = {:.3f})'.format(auc(recall[0],prec[0])))\n",
    "plt.plot(recall[1], prec[1],color='green', label='Alphas (area = {:.3f})'.format(auc(recall[1],prec[1])))\n",
    "plt.plot(recall[2], prec[2],color='blue', label='Gamma (area = {:.3f})'.format(auc(recall[2],prec[2])))\n",
    "plt.plot(recall[3], prec[3],color='yellow', label='Neutrons (area = {:.3f})'.format(auc(recall[3],prec[3])))\n",
    "plt.title('Multiclass precision recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisioy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(recall_thresh[0], F1[0],color='orange', label='Electrons')\n",
    "plt.plot(recall_thresh[1], F1[1],color='green', label='Alphas')\n",
    "plt.plot(recall_thresh[2], F1[2],color='blue', label='Gamma')\n",
    "plt.plot(recall_thresh[3], F1[3],color='yellow', label='Neutron')\n",
    "plt.title('F1 score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'],label='Loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['auc'],label='auc')\n",
    "plt.plot(history.history['val_auc'],label='Validation auc')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['categorical_accuracy'],label='categorical accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'],label='Validation categorical accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('categorical accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(proba[:,0],bins=150,stacked=True,density=True,color='orange')\n",
    "plt.title(\"Probability of Electron\")\n",
    "plt.xlabel('Probability of Electron')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(proba[:,1],bins=150,stacked=True,density=True,color='green')\n",
    "plt.title(\"Probability of Alpha\")\n",
    "plt.xlabel('Probability of Alpha')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(proba[:,2],bins=150,stacked=True,density=True,color='blue')\n",
    "plt.title(\"Probability of Gamma\")\n",
    "plt.xlabel('Probability of Gamma')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(proba[:,3],bins=150,stacked=True,density=True,color='yellow')\n",
    "plt.title(\"Probability of Neutron\")\n",
    "plt.xlabel('Probability of Neutron')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(proba[:,0],bins=150,histtype='step',stacked=True,density=True,color='orange',label='electron')\n",
    "plt.hist(proba[:,1],bins=150,histtype='step',stacked=True,density=True,color='green',label='alpha')\n",
    "plt.hist(proba[:,2],bins=150,histtype='step',stacked=True,density=True,color='blue',label='gamma')\n",
    "plt.hist(proba[:,3],bins=150,histtype='step',stacked=True,density=True,color='yellow',label='neutron')\n",
    "plt.title(\"Probability\")\n",
    "plt.xlabel('Probability')\n",
    "plt.show()\n",
    "#confusion=confusion_matrix(labels_test, predictions)\n",
    "#NN_metrics=confusion_metrics(confusion,sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287314bf-c885-48b2-a28f-56390b4eae36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b113e-4e6c-44b1-bc98-6535f84eb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns={'sample' : [],'accuracy' : [], 'recall' : [], 'precision' : [], 'F1 score' : [], 'specificity' : []}\n",
    "NN_metrics=pd.DataFrame(np.asarray(NN_metrics_list),columns=columns)\n",
    "NN_metrics['method']='multiclassifier'\n",
    "\n",
    "metrics['sample']=['electron','alpha','neutron','gamma']\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "comparison_metrics=pd.concat([NN_metrics,metrics])\n",
    "comparison_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90928b3-6d80-4c0c-97a2-58c056038f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cad5a3-b6e6-446d-a55f-42d06b16e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f81154-56d3-47c3-a99e-87bf1814d7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb7d13-70d7-499b-8e40-b1b792d93863",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(roc_metrics_electron_alpha['FPR'], roc_metrics_electron_alpha['TPR'], label='Electrons vs Alpha (area = {:.3f})'.format(roc_metrics_electron_alpha['auc-roc'].max()))\n",
    "plt.plot(roc_metrics_gamma_neutron['FPR'], roc_metrics_gamma_neutron['TPR'], label='Gamma vs Neutrons (area = {:.3f})'.format(roc_metrics_gamma_neutron['auc-roc'].max()))\n",
    "plt.plot(roc_metrics_gamma_electron['FPR'], roc_metrics_gamma_electron['TPR'], label='Gamma vs Electrons (area = {:.3f})'.format(roc_metrics_gamma_electron['auc-roc'].max()))\n",
    "plt.plot(roc_metrics_electron_neutron['FPR'], roc_metrics_electron_neutron['TPR'], label='Electrons vs Neutrons (area = {:.3f})'.format(roc_metrics_electron_neutron['auc-roc'].max()))\n",
    "plt.plot(roc_metrics_chains['FPR'], roc_metrics_chains['TPR'], label='Decay chains (area = {:.3f})'.format(roc_metrics_chains['auc-roc'].max()))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e2460-eccb-4691-94a9-6ee3541a267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14472e4-3b8f-49af-9691-83a8aa32f6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecb80b-ac59-4bd4-ade8-7e230de2f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_data=info[0]\n",
    "alpha_data=info[1]\n",
    "neutron_data=info[2]\n",
    "gamma_data=info[3]\n",
    "\n",
    "#electron_max=electron_data[electron_data['F1 score'] == electron_data['F1 score'].max()]\n",
    "electron_metrics=electron_data[electron_data['minval']== 0]\n",
    "auc_electron=auc(1-electron_metrics['specificity'], electron_metrics['recall'])\n",
    "#pr_auc_electron=auc(electron_metrics['precision'], electron_metrics['recall'])\n",
    "\n",
    "#alpha_max=alpha_data[alpha_data['F1 score'] == alpha_data['F1 score'].max()]\n",
    "alpha_metrics=alpha_data[alpha_data['minval']== 0]\n",
    "auc_alpha=auc(1-alpha_metrics['specificity'], alpha_metrics['recall'])\n",
    "#pr_auc_alpha=auc(alpha_metrics['precision'], alpha_metrics['recall'])\n",
    "\n",
    "\n",
    "#neutron_max=neutron_data[neutron_data['F1 score'] == neutron_data['F1 score'].max()]\n",
    "neutron_metrics=neutron_data[neutron_data['minval']== 0]\n",
    "auc_neutron=auc(1-neutron_metrics['specificity'], neutron_metrics['recall'])\n",
    "#pr_auc_neutron=auc(neutron_metrics['precision'], neutron_metrics['recall'])\n",
    "\n",
    "#gamma_max=gamma_data[gamma_data['F1 score'] == gamma_data['F1 score'].max()]\n",
    "gamma_metrics=gamma_data[gamma_data['minval']== 0]\n",
    "auc_gamma=auc(1-gamma_metrics['specificity'], gamma_metrics['recall'])\n",
    "#pr_auc_gamma=auc(gamma_metrics['precision'], gamma_metrics['recall'])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(1-electron_metrics['specificity'],electron_metrics['recall'],color='orange',label='cut electron(area = {:.3f})'.format(auc_electron))\n",
    "plt.plot(1-alpha_metrics['specificity'],alpha_metrics['recall'],color='green',label='cut alpha(area = {:.3f})'.format(auc_alpha))\n",
    "plt.plot(1-neutron_metrics['specificity'],neutron_metrics['recall'],color='blue',label='cut gamma(area = {:.3f})'.format(auc_neutron))\n",
    "plt.plot(1-gamma_metrics['specificity'],gamma_metrics['recall'],color='yellow',label='cut neutron(area = {:.3f})'.format(auc_gamma))\n",
    "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='NN Electrons (area = {:.3f})'.format(auc(fpr[0],tpr[0])))\n",
    "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='NN Alphas (area = {:.3f})'.format(auc(fpr[1],tpr[1])))\n",
    "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='NN Gamma (area = {:.3f})'.format(auc(fpr[2],tpr[2])))\n",
    "plt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='NN Neutrons (area = {:.3f})'.format(auc(fpr[3],tpr[3])))\n",
    "plt.plot([0, 1], [0, 1],linestyle='dashdot',color='red', label='No classifier')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(1-electron_metrics['recall'],electron_metrics['precision'],color='orange',label='cut electron(area = {:.3f})'.format(auc_electron))\n",
    "plt.plot(1-alpha_metrics['recall'],alpha_metrics['precision'],color='green',label='cut alpha(area = {:.3f})'.format(auc_alpha))\n",
    "plt.plot(1-neutron_metrics['recall'],neutron_metrics['precision'],color='blue',label='cut gamma(area = {:.3f})'.format(auc_neutron))\n",
    "plt.plot(1-gamma_metrics['recall'],gamma_metrics['precision'],color='yellow',label='cut neutron(area = {:.3f})'.format(auc_gamma))\n",
    "plt.plot(recall[0], prec[0],color='orange', label='NN Electrons (area = {:.3f})'.format(auc(recall[0],prec[0])))\n",
    "plt.plot(recall[1], prec[1],color='green', label='NN Alphas (area = {:.3f})'.format(auc(recall[1],prec[1])))\n",
    "plt.plot(recall[2], prec[2],color='blue', label='NN Gamma (area = {:.3f})'.format(auc(recall[2],prec[2])))\n",
    "plt.plot(recall[3], prec[3],color='yellow', label='NN Neutrons (area = {:.3f})'.format(auc(recall[3],prec[3])))\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599faaf4-865f-491d-a348-85c2eef58e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "pr_metrics_po212_na22=pr_metrics_po212_na22.dropna()\n",
    "pr_metrics_bi212_po212=pr_metrics_bi212_po212.dropna()\n",
    "pr_metrics_neutron_na22=pr_metrics_neutrons_na22.dropna()\n",
    "pr_metrics_neutron_bi212=pr_metrics_bi212_neutrons.dropna()\n",
    "\n",
    "plt.plot(pr_metrics_po212_na22['thresholds'],pr_metrics_po212_na22['precision'], label='po212 vs na22 precision')\n",
    "plt.plot(pr_metrics_bi212_po212['thresholds'],pr_metrics_bi212_po212['precision'], label='po212 vs bi212 precision')\n",
    "plt.plot(pr_metrics_neutron_na22['thresholds'],pr_metrics_neutron_na22['precision'], label='neutron vs na22 precision')\n",
    "plt.plot(pr_metrics_neutron_bi212['thresholds'],pr_metrics_neutron_bi212['precision'], label='neutron vs na22 precision')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Varying threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(pr_metrics_po212_na22['thresholds'],pr_metrics_po212_na22['recall'], label= 'po212 vs na22 recall')\n",
    "plt.plot(pr_metrics_bi212_po212['thresholds'],pr_metrics_bi212_po212['recall'], label= 'po212 vs bi212 recall')\n",
    "plt.plot(pr_metrics_neutron_na22['thresholds'],pr_metrics_neutron_na22['recall'], label= 'neutron vs na22 recall')\n",
    "plt.plot(pr_metrics_neutron_bi212['thresholds'],pr_metrics_neutron_bi212['recall'], label= 'neutron vs na22 recall')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Varying threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(roc_metrics_po212_na22['thresholds'],(2*pr_metrics_po212_na22['recall']*pr_metrics_po212_na22['precision'])/(pr_metrics_po212_na22['recall']+pr_metrics_po212_na22['precision'][:-1]), label= 'po212 vs na22 F1 score')\n",
    "plt.plot(roc_metrics_bi212_po212['thresholds'],(2*pr_metrics_bi212_po212['recall']*pr_metrics_bi212_po212['precision'])/(pr_metrics_bi212_po212['recall']+pr_metrics_bi212_po212['precision'][:-1]), label= 'po212 vs bi212 F1 score')\n",
    "plt.plot(roc_metrics_neutron_na22['thresholds'],(2*pr_metrics_neutron_na22['recall']*pr_metrics_neutron_na22['precision'])/(pr_metrics_neutron_na22['recall']+pr_metrics_neutron_na22['precision'][:-1]), label= 'neutron vs na22 F1 score')\n",
    "plt.plot(roc_metrics_neutron_bi212['thresholds'],(2*pr_metrics_neutron_bi212['recall']*pr_metrics_neutron_bi212['precision'])/(pr_metrics_neutron_bi212['recall']+pr_metrics_neutron_bi212['precision'][:-1]), label= 'neutron vs na22 F1 score')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('Varying threshold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599f055-19ac-4092-b677-54f7fd1c358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['Pulse Area', 'Coincidence', 'Peak Time', 'Peak Amp', 'Pulse Length', 'Area/time']\n",
    "accuracy=[0.915,0.842,0.859,0.822,0.845,0.889]\n",
    "recall=[0.935,0.476,0.777,0.376,0.762,0.738]\n",
    "precision=[0.778,0.844,0.705,0.851,0.687,0.812]\n",
    "F1=[0.858,0.609,0.739,0.521,0.722,0.774]\n",
    "specificity=[0.907,0.969,0.887,0.977,0.880,0.941]\n",
    "\n",
    "\n",
    "width = 0.35 \n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "X = np.arange(6)\n",
    "ax.bar(X-0.25, recall, width = 0.25,label=\"Recall\")\n",
    "ax.bar(X , precision, width = 0.25,label=\"Precision\")\n",
    "ax.bar(X + 0.25, F1, width = 0.25,label=\"F1\")\n",
    "ticks=[0,1,2,3,4,5]\n",
    "ax.set_xticks(ticks, labels)\n",
    "ax.set_ylabel('Metrics')\n",
    "ax.set_title('Metrics for different features')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba4085-b7e9-428f-bfdc-f9a99d965a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_bi212_po212.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a49bc9-b71e-41d7-af1a-181243cdcd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history_bi212_po212.history['val_accuracy'],label='Bi212-Po212')\n",
    "plt.plot(history_neutrons_na22.history['val_accuracy'],label='neutron-na22')\n",
    "plt.plot(history_bi212_neutrons.history['val_accuracy'],label='Bi212-neutron')\n",
    "plt.plot(history_po212_na22.history['val_accuracy'],label='Po212-Na22')\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend( loc='best')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history_bi212_po212.history['val_loss'],label='Bi212-Po212')\n",
    "plt.plot(history_neutrons_na22.history['val_loss'],label='neutron-na22')\n",
    "plt.plot(history_bi212_neutrons.history['val_loss'],label='Bi212-neutron')\n",
    "plt.plot(history_po212_na22.history['val_loss'],label='Po212-Na22')\n",
    "plt.title('validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend( loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937cb891-9c82-4972-9f74-2c7de9ee0507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb8f38-8b37-42dd-9138-1cf275b7daa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
